# Анализ логов с использованием PySpark

Этот проект включает две части: генерацию информации и анализ данных.

## Часть 1. Генерация информации

Используя библиотеку Faker для генерации логов веб-сервера, было создано 100,000 записей логов, содержащих информацию об IP-адресе клиента, временной метке запроса, HTTP-методе, URL запроса, коде ответа и размере ответа в байтах. Сгенерированные данные были сохранены в CSV-файл.

## Часть 2. Анализ информации

1. **Топ 10 самых активных IP адресов:**
   Были сгруппированы данные по IP и посчитано количество запросов для каждого IP, затем были выведены 10 самых активных IP адресов.

2. **Количество запросов по HTTP методу:**
   Данные были сгруппированы по HTTP методу и подсчитано количество запросов для каждого метода.

3. **Количество запросов с кодом ответа 404:**
   Данные были отфильтрованы, чтобы найти количество запросов с кодом ответа 404.

4. **Общий размер ответов по дням:**
   Данные были сгруппированы по дате и просуммирован размер ответов в байтах, затем отсортированы по дате.

Код и результаты анализа представлены выше. Все шаги анализа выполнены с использованием PySpark на платформе Google Colab.

Оригинальный файл доступен по [этой ссылке](https://colab.research.google.com/drive/1b69G0OqGRIGWeHyUvYEXzw2spCqXz5n-).

Автор: Катерина Лаппа