{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSz0X7L6j8Ga"
      },
      "source": [
        "# **Задание**\n",
        "\n",
        "Задание состоит из двух частей.\n",
        "\n",
        "# Часть 1. Генерация информации\n",
        "Используя библиотеку для генерации логов веб-сервера сгенерируйте 100 000 записей логов и сохраните их в CSV-файл.\n",
        "\n",
        "Логи содержат следующую информацию:\n",
        "\n",
        "IP-адрес клиента\n",
        "\n",
        "Временная метка запроса\n",
        "\n",
        "HTTP-метод (GET, POST, etc.)\n",
        "\n",
        "URL запроса\n",
        "\n",
        "Код ответа (200, 404, etc.)\n",
        "\n",
        "Размер ответа в байтах\n",
        "\n",
        "Сгенерировали 100,000 записей логов и сохранили их в CSV-файл.\n",
        "\n",
        "\n",
        "# Часть 2. Анализ информации\n",
        "1. Сгруппируйте данные по IP и посчитайте количество запросов для каждого IP, выводим 10 самых активных IP. Формат вывода, как на скрине ниже.\n",
        "\n",
        "2. Сгруппируйте данные по HTTP-методу и посчитайте количество запросов для каждого метода.\n",
        "\n",
        "3. Профильтруйте и посчитайте количество запросов с кодом ответа 404.\n",
        "\n",
        "4. Сгруппируйте данные по дате и просуммируйте размер ответов, сортируйте по дате."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nszIPdseGvfz",
        "outputId": "b3a8adf2-7aed-4f91-9ab4-7b828c882c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-30.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-30.0.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-30.0.0\n",
            "Сгенерировано 100000 записей и сохранено в web_server_logs.csv\n"
          ]
        }
      ],
      "source": [
        "# Сгенерируем 100 000 записей логов и сохраним их в CSV-файл:\n",
        "\n",
        "!pip install faker\n",
        "import csv\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "num_records = 100000\n",
        "\n",
        "http_methods = ['GET', 'POST', 'PUT', 'DELETE']\n",
        "response_codes = [200, 301, 404, 500]\n",
        "\n",
        "file_path = \"web_server_logs.csv\"\n",
        "\n",
        "with open(file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['ip', 'timestamp', 'method', 'url', 'response_code', 'response_size'])\n",
        "\n",
        "    for _ in range(num_records):\n",
        "        ip = fake.ipv4()\n",
        "        timestamp = fake.date_time_this_year().isoformat()\n",
        "        method = random.choice(http_methods)\n",
        "        url = fake.uri_path()\n",
        "        response_code = random.choice(response_codes)\n",
        "        response_size = random.randint(100, 10000)\n",
        "\n",
        "        writer.writerow([ip, timestamp, method, url, response_code, response_size])\n",
        "\n",
        "print(f\"Сгенерировано {num_records} записей и сохранено в {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlc0zFQArZjX",
        "outputId": "78fa44fe-cf7a-47fa-c58f-45f7848126de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
          ]
        }
      ],
      "source": [
        "pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aecekRiZiSAv",
        "outputId": "e8124c18-c191-43f6-f456-89ede6e5604a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=98ea62e8e3fe1491cd77950388d33015109ad5fcea4fe6520b8d6aa4f225ca1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "#Устанавливаем pySpark\n",
        "!pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x2O0hJtKjz3Z"
      },
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, sum, to_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "duoYLoUkjZbU"
      },
      "outputs": [],
      "source": [
        "# Создание SparkSession\n",
        "spark = SparkSession.builder.appName('Logs').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ctIZZwe3hkqN"
      },
      "outputs": [],
      "source": [
        "# Установка уровня логирования на \"ERROR\"\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-aC-ew-Aj8It"
      },
      "outputs": [],
      "source": [
        "# Чтение данных\n",
        "logs_df = spark.read.csv('/content/web_server_logs.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijT275qxWlta",
        "outputId": "a757ee08-e62a-475b-f20b-a8fbcd5ed57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 active IP addresses:\n",
            "+---------------+-------------+\n",
            "|             ip|request_count|\n",
            "+---------------+-------------+\n",
            "|  76.67.201.232|            2|\n",
            "|   5.170.144.66|            1|\n",
            "|    83.122.4.83|            1|\n",
            "| 140.191.48.149|            1|\n",
            "| 171.168.215.28|            1|\n",
            "|   95.138.3.198|            1|\n",
            "| 19.215.209.222|            1|\n",
            "|145.205.208.170|            1|\n",
            "|  82.101.42.156|            1|\n",
            "|203.199.245.254|            1|\n",
            "+---------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Сгруппируем данные по IP и посчитаем количество запросов для каждого IP, выводим 10 самых активных IP:\n",
        "\n",
        "top_addresses = logs_df.groupBy('ip').agg(count(col('timestamp')).alias('request_count')).orderBy(col('request_count').desc()).limit(10)\n",
        "print('Top 10 active IP addresses:')\n",
        "top_addresses.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg50znruZLN6",
        "outputId": "059aff3a-c3c8-4ac2-eb9f-4176c084883e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requests count by HTTP method:\n",
            "+------+------------+\n",
            "|method|method_count|\n",
            "+------+------------+\n",
            "|  POST|       25036|\n",
            "|DELETE|       24954|\n",
            "|   PUT|       25063|\n",
            "|   GET|       24947|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2.Сгруппируем данные по HTTP-методу и посчитаем количество запросов для каждого метода:\n",
        "\n",
        "requests_count = logs_df.groupBy('method').agg(count(col('method')).alias('method_count'))\n",
        "print('Requests count by HTTP method:')\n",
        "requests_count.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQo_eKCKsTCx",
        "outputId": "2dfcd2b9-f88c-4021-d404-d853ef0fff31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of 404 response codes: 25300\n"
          ]
        }
      ],
      "source": [
        "# 3.Отфильтруем данные и посчитаем количество запросов с кодом ответа 404:\n",
        "\n",
        "responses_404 = logs_df.filter(col('response_code') == 404).count()\n",
        "print(f'Number of 404 response codes: {responses_404}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2kOlKZec42C",
        "outputId": "eea55e54-0ffc-4924-a598-37b676cd3958"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ip', 'string'),\n",
              " ('timestamp', 'date'),\n",
              " ('method', 'string'),\n",
              " ('url', 'string'),\n",
              " ('response_code', 'int'),\n",
              " ('response_size', 'int')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4.Сгруппируем данные по дате и просуммируем размер ответов, сортировка по дате.\n",
        "\n",
        "# Преобразуем столбец timestamp  в формат даты:\n",
        "logs_df = logs_df.withColumn('timestamp', to_date(col('timestamp'), \"yyyy-MM-dd\"))\n",
        "\n",
        "# Проверяем типы данных:\n",
        "logs_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVb3tRwM2st_",
        "outputId": "cc34cc08-a00d-4a03-8319-ebada327a395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total response size by day:\n",
            "+----------+-------------------+\n",
            "|      date|total_response_size|\n",
            "+----------+-------------------+\n",
            "|2024-01-01|            2006720|\n",
            "|2024-01-02|            1922129|\n",
            "|2024-01-03|            1920184|\n",
            "|2024-01-04|            1883820|\n",
            "|2024-01-05|            1923729|\n",
            "|2024-01-06|            1863618|\n",
            "|2024-01-07|            1840074|\n",
            "|2024-01-08|            1969014|\n",
            "|2024-01-09|            1680912|\n",
            "|2024-01-10|            1841812|\n",
            "|2024-01-11|            1843664|\n",
            "|2024-01-12|            1673963|\n",
            "|2024-01-13|            1753178|\n",
            "|2024-01-14|            1849427|\n",
            "|2024-01-15|            1792300|\n",
            "|2024-01-16|            1741818|\n",
            "|2024-01-17|            1739419|\n",
            "|2024-01-18|            1806903|\n",
            "|2024-01-19|            1763054|\n",
            "|2024-01-20|            1755199|\n",
            "+----------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_response_size = logs_df.groupBy(col('timestamp').alias('date')).agg(sum(col('response_size')).alias('total_response_size')).orderBy('date')\n",
        "print('Total response size by day:')\n",
        "total_response_size.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
